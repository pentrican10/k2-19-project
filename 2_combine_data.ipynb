{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd9a379-e681-400d-959e-30ed675e3da8",
   "metadata": {},
   "source": [
    "# Combine data from TESS, Petigura, and Narita\n",
    "Assuring same time offsets and ephem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de550769-29e9-49bc-952c-3ab152765b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightkurve as lk\n",
    "from lightkurve import search_targetpixelfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import batman\n",
    "from scipy.stats import norm\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1de7706-5fd9-4a0a-b1d8-e52aba65cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/pentrican10/Projects/k2-19-project/data\n"
     ]
    }
   ],
   "source": [
    "### Define data directory\n",
    "working_dir = os.getcwd()\n",
    "data_dir = os.path.join(working_dir, \"data\")\n",
    "print(f\"Data directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "888b2fbe-ae85-49de-a344-6b100ede1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_offset = 2457000\n",
    "petigura_offset = 2454833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92b0c593-c78c-4862-86f7-2c6465b5b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/wlx91x8s1x34mphlfjy0h4pm0000gn/T/ipykernel_69822/2146133021.py:11: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file_path, delim_whitespace=True, skiprows=22, names=columns)\n"
     ]
    }
   ],
   "source": [
    "### read table from Petigura et al. 2020\n",
    "file = \"ajab5220t1_mrt.txt\"\n",
    "def read_table(file_name):\n",
    "    ### path to table - Petigura et al 2020\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "    ### Define the column names \n",
    "    columns = [\"Planet\", \"Transit\", \"Inst\", \"Tc\", \"e_Tc\", \"Source\"]\n",
    "\n",
    "    ### Read the text file, specifying space as the delimiter, skipping model_guess_omc rows\n",
    "    df = pd.read_csv(file_path, delim_whitespace=True, skiprows=22, names=columns)\n",
    "\n",
    "    ### Remove NaN values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "df_petigura = read_table(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca930efb-4359-48f8-a774-044a6da70083",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Petigura data\n",
    "planet_b_data = df_petigura[df_petigura[\"Planet\"] == \"K2-19b\"]\n",
    "planet_c_data = df_petigura[df_petigura[\"Planet\"] == \"K2-19c\"]\n",
    "\n",
    "petigura_ind = np.array(planet_b_data[\"Transit\"]) \n",
    "\n",
    "period_b_petigura = 7.9222 # [days]\n",
    "tc_b_petigura = 2027.9023 # [days] using petigura offset\n",
    "period_c_petigura = 11.8993 # [days]\n",
    "tc_c_petigura = 2020.0007 # [days] using petigura offset\n",
    "\n",
    "### transit times\n",
    "tc_petigura_b = np.array(planet_b_data[\"Tc\"])\n",
    "tc_petigura_c = np.array(planet_c_data[\"Tc\"])\n",
    "\n",
    "### update index (misalignment in paper indices and tc)\n",
    "petigura_ind_b_updated = np.array(planet_b_data[\"Transit\"]) - 6\n",
    "petigura_ind_c_updated = np.array(planet_c_data[\"Transit\"]) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c6fc251-a40e-4519-8673-f97c0457af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/wlx91x8s1x34mphlfjy0h4pm0000gn/T/ipykernel_69822/4284132366.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_narita = pd.read_csv('narita_times.txt', delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "### Narita data\n",
    "### get Narita et al times (K2)\n",
    "df_narita = pd.read_csv('narita_times.txt', delim_whitespace=True)\n",
    "df_narita_b = df_narita[df_narita[\"planet_num\"] == 1]\n",
    "tc_narita_b = np.array(df_narita_b[\"Tc\"]) - petigura_offset\n",
    "df_narita_c = df_narita[df_narita[\"planet_num\"] == 2]\n",
    "tc_narita_c = np.array(df_narita_c[\"Tc\"]) - petigura_offset\n",
    "\n",
    "### put times into petigura ephem (shift epoch by -6)\n",
    "narita_ind_b = [-6, -5, -4, -3, -2, -1, 0, 1, 2, 3]\n",
    "narita_ind_b = np.array(narita_ind_b)\n",
    "narita_ind_c = [-3, -2, -1, 0, 1, 2, 3]\n",
    "narita_ind_c = np.array(narita_ind_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86da4b43-305d-40ee-a34e-7043739800ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESS data\n",
    "### tess times in the paper ephem\n",
    "tnum_tess = [337,339,340,341,342,343,430,432]\n",
    "\n",
    "### updated indices for petigura ephem\n",
    "df_tess = pd.read_csv('tess_transit_data.csv')\n",
    "tess_ind_b = np.array(df_tess[\"Transit\"]) + 337\n",
    "tc_tess_b = np.array(df_tess[\"Tc(TESS)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31201f9c-a8bb-4f8d-8200-71504c12ef17",
   "metadata": {},
   "source": [
    "### Planet b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67340ddd-26da-4aff-af89-8601107e407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect all data together\n",
    "### collect all transit indices\n",
    "all_transit_num_b = []\n",
    "for i in range(len(narita_ind_b)):\n",
    "    all_transit_num_b.append(narita_ind_b[i])\n",
    "for i in range(len(petigura_ind_b_updated)):\n",
    "    all_transit_num_b.append(petigura_ind_b_updated[i])\n",
    "for i in range(len(tess_ind_b)):\n",
    "    all_transit_num_b.append(tess_ind_b[i])\n",
    "# print(f\"All transit indices: {all_transit_num_b}\")\n",
    "\n",
    "### collect all observed transit times\n",
    "all_obs_tc_b = []\n",
    "for i in range(len(tc_narita_b)):\n",
    "    all_obs_tc_b.append(tc_narita_b[i])\n",
    "for i in range(len(tc_petigura_b)):\n",
    "    all_obs_tc_b.append(tc_petigura_b[i])\n",
    "for i in range(len(tc_tess_b)):\n",
    "    all_obs_tc_b.append(tc_tess_b[i])\n",
    "# print(f\"All observed transit times: {all_obs_tc_b}\")\n",
    "\n",
    "### collect all observed transit time errors\n",
    "all_obs_tc_b_err = []\n",
    "tc_b_err_narita = np.array(df_narita_b[\"Tc_err\"])\n",
    "tc_b_err_tess = np.array(df_tess[\"Tc_err\"])\n",
    "tc_b_err_petigura = np.array(planet_b_data[\"e_Tc\"])\n",
    "for i in range(len(tc_b_err_narita)):\n",
    "    all_obs_tc_b_err.append(tc_b_err_narita[i])\n",
    "for i in range(len(tc_b_err_petigura)):\n",
    "    all_obs_tc_b_err.append(tc_b_err_petigura[i])\n",
    "for i in range(len(tc_b_err_tess)):\n",
    "    all_obs_tc_b_err.append(tc_b_err_tess[i])\n",
    "# print(f\"All observed transit times error: {all_obs_tc_b_err}\")\n",
    "\n",
    "### collect all calculated transit times with petigura ephem\n",
    "all_calc_tc_b = []\n",
    "for i in range(len(all_transit_num_b)):\n",
    "    ind = tc_b_petigura + (all_transit_num_b[i] * period_b_petigura)\n",
    "    all_calc_tc_b.append(ind)\n",
    "# print(f\"All calculated transit times: {all_calc_tc_b}\")\n",
    "\n",
    "### collect all omc\n",
    "all_omc_b = []\n",
    "for i in range(len(all_calc_tc_b)):\n",
    "    omc_ = all_obs_tc_b[i] - all_calc_tc_b[i]\n",
    "    all_omc_b.append(omc_)\n",
    "# print(f\"All OMC: {all_omc_b}\")\n",
    "\n",
    "all_omc_b_err = all_obs_tc_b_err\n",
    "# print(f\"All OMC err: {all_omc_b_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21bc3e9-3d16-47ce-a66c-7b6c9fb61e8d",
   "metadata": {},
   "source": [
    "### Planet c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9792ee3e-06b4-442f-98c5-2f0f3b644007",
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect all values for planet c\n",
    "### collect all transit indices\n",
    "all_transit_num_c = []\n",
    "for i in range(len(narita_ind_c)):\n",
    "    all_transit_num_c.append(narita_ind_c[i])\n",
    "for i in range(len(petigura_ind_c_updated)):\n",
    "    all_transit_num_c.append(petigura_ind_c_updated[i])\n",
    "\n",
    "# print(f\"All transit indices c: {all_transit_num_c}\")\n",
    "\n",
    "### collect all observed transit times\n",
    "all_obs_tc_c = []\n",
    "for i in range(len(tc_narita_c)):\n",
    "    all_obs_tc_c.append(tc_narita_c[i])\n",
    "for i in range(len(tc_petigura_c)):\n",
    "    all_obs_tc_c.append(tc_petigura_c[i])\n",
    "\n",
    "# print(f\"All observed transit times c: {all_obs_tc_c}\")\n",
    "\n",
    "### collect all observed transit time errors\n",
    "all_obs_tc_c_err = []\n",
    "tc_c_err_narita = np.array(df_narita_c[\"Tc_err\"])\n",
    "tc_c_err_petigura = np.array(planet_c_data[\"e_Tc\"])\n",
    "for i in range(len(tc_c_err_narita)):\n",
    "    all_obs_tc_c_err.append(tc_c_err_narita[i])\n",
    "for i in range(len(tc_c_err_petigura)):\n",
    "    all_obs_tc_c_err.append(tc_c_err_petigura[i])\n",
    "# print(f\"All observed transit times error c: {all_obs_tc_c_err}\")\n",
    "\n",
    "### collect all calculated transit times with petigura ephem\n",
    "all_calc_tc_c = []\n",
    "for i in range(len(all_transit_num_c)):\n",
    "    ind = tc_c_petigura + (all_transit_num_c[i] * period_c_petigura)\n",
    "    all_calc_tc_c.append(ind)\n",
    "# print(f\"All calculated transit times c: {all_calc_tc_c}\")\n",
    "\n",
    "### collect all omc\n",
    "all_omc_c = []\n",
    "for i in range(len(all_calc_tc_c)):\n",
    "    omc_ = all_obs_tc_c[i] - all_calc_tc_c[i]\n",
    "    all_omc_c.append(omc_)\n",
    "# print(f\"All OMC c: {all_omc_c}\")\n",
    "\n",
    "all_omc_c_err = all_obs_tc_c_err\n",
    "# print(f\"All OMC err c: {all_omc_c_err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7d5b6-a5f8-431d-bb89-012b9117f1f1",
   "metadata": {},
   "source": [
    "# Save Results in File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53032a3-3b80-40ac-86d1-bd426a1820a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make txt file with results \n",
    "output_file = \"ttv_results.txt\"\n",
    "\n",
    "### Combine all data into a structured format\n",
    "source = ['Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', # b\n",
    "          'Petigura2020', 'Petigura2020', 'Petigura2020', 'Petigura2020', 'Petigura2020', 'Petigura2020', # b\n",
    "          'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', # b\n",
    "          'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', 'Narita2015', # c\n",
    "          'Petigura2020', 'Petigura2020'] # c\n",
    "\n",
    "instrument = ['K2', 'K2', 'K2', 'K2', 'K2', 'K2', 'K2', 'K2', 'K2', 'K2', # b\n",
    "          'FLWO', 'TRAPPIST', 'MuSCAT', 'Spitzer', 'LCO', 'Spitzer',  # b\n",
    "          'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', 'TESS', # b\n",
    "          'K2', 'K2', 'K2', 'K2', 'K2', 'K2', 'K2', # c\n",
    "          'Spitzer', 'Spitzer'] # c\n",
    "\n",
    "planet_number = []\n",
    "for i in range(len(all_obs_tc_b)):\n",
    "    planet_number.append(1)\n",
    "for i in range(len(all_obs_tc_c)):\n",
    "    planet_number.append(2)\n",
    "\n",
    "all_transit_num = [] \n",
    "for i in range(len(all_transit_num_b)):\n",
    "    all_transit_num.append(all_transit_num_b[i])\n",
    "for i in range(len(all_transit_num_c)):\n",
    "    all_transit_num.append(all_transit_num_c[i])\n",
    "\n",
    "all_obs_tc = []\n",
    "for i in range(len(all_obs_tc_b)):\n",
    "    all_obs_tc.append(all_obs_tc_b[i])\n",
    "for i in range(len(all_obs_tc_c)):\n",
    "    all_obs_tc.append(all_obs_tc_c[i])\n",
    "\n",
    "all_obs_tc_err = []\n",
    "for i in range(len(all_obs_tc_b_err)):\n",
    "    all_obs_tc_err.append(all_obs_tc_b_err[i])\n",
    "for i in range(len(all_obs_tc_c_err)):\n",
    "    all_obs_tc_err.append(all_obs_tc_c_err[i])\n",
    "\n",
    "# all_omc = []\n",
    "# for i in range(len(all_omc_b)):\n",
    "#     all_omc.append(all_omc_b[i])\n",
    "# for i in range(len(all_omc_c)):\n",
    "#     all_omc.append(all_omc_c[i])\n",
    "\n",
    "### Ensure source and instrument are numpy arrays with dtype=object\n",
    "source = np.array(source, dtype=object)\n",
    "instrument = np.array(instrument, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42571dcc-ed4f-453c-aac5-421bd3274de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ttv_results.txt\n"
     ]
    }
   ],
   "source": [
    "### save\n",
    "data_to_save = np.column_stack((planet_number, all_transit_num, all_obs_tc, all_obs_tc_err, source, instrument))\n",
    "\n",
    "### Define header\n",
    "header = \"Planet_num Index Tc Tc_err Source Instrument\"\n",
    "\n",
    "### Save to file\n",
    "np.savetxt(output_file, data_to_save, fmt='%d %d %.8f %.8f %s %s', header=header, comments='')\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f9e38-1e3a-4729-9a4b-a0d58d546a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
